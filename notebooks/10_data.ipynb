{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and synthethize networks of different classes\n",
    "\n",
    "In this chapter we are going to prepare the data for the next chapters.\n",
    "We will also create a synthetic network of each class.\n",
    "\n",
    "Different Datasets:\n",
    "\n",
    "- MS2265: Mass spectral database NIST\n",
    "- N9: Exhausitve, non-isomorphic, connected graph with 9 vertices (Nauty)\n",
    "- T15: Exhausitve, non-isomorphic, connected tree-graph with 15 vertices (Nauty)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a set of graphs from \"On structure-sensitivity of degree-based topological indices\"\n",
    "\n",
    "Let $G$ be a graph. Start be settings $\\mathscr{S}(G) = \\emptyset$. Delete from $G$ an edge and insert into it another edge. Do this in all possible ways.\n",
    "\n",
    "Let $G'$ be a graph obtained by delete from $G$ an edge, and by inserting into it another edge. If $G'$ is not connected, then disregard it. If $G' \\cong G$ (isomorphic) then disregard $G'$.\n",
    "If $G'$ is connected, check wether it is isomorphic to any of the elements of $\\mathscr{S}(G)$. If yes, disregard it. If not, include $G'$ into the set $\\mathscr{S}(G)$.\n",
    "\n",
    "Do the transformation $G \\rightarrow G'$ in all possible ways.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n",
    "\n",
    "Im ./data Verzeichnis befinden sich alle Graphen als bliss oder g6 Dateien.\n",
    "Wir importieren diese und speichern sie in einer Liste.\n",
    "\n",
    "### Beschreibung der Daten\n",
    "\n",
    "- all_graphs\n",
    "  - Format: .g6\n",
    "  - Beschreibung: Alle graphen bis zu 9 Knoten\n",
    "  - Quelle: [Brendan McKay](http://users.cecs.anu.edu.au/~bdm/data/graphs.html)\n",
    "- complete\n",
    "  - Format: DIMACS\n",
    "  - Beschreibung: Alle vollständigen Graphen bis zu 100 Knoten\n",
    "  - Quelle: networkx / Luca Hostettler\n",
    "- hypercubes\n",
    "  - Format: DIMACS\n",
    "  - Beschreibung: Alle Hypercubes 3 bis 21 \"dimensional\"\n",
    "  - Quelle: networkx / Luca Hostettler\n",
    "- ran2, ran10, ransq\n",
    "  - Format: DIMACS\n",
    "  - Beschreibung: Kanten mit Wahrscheinlichkeit $frac(1/2)$, $frac(110)$, $1/sqrt(n)$, $5-5000$, $10 - 10000$, $2^5 - 2^17$ Knoten\n",
    "  - Quelle: [Brendan McKay](http://users.cecs.anu.edu.au/~bdm/data/graphs.html)\n",
    "- ranreg:\n",
    "  - Format: DIMACS\n",
    "  - Beschreibung: Random reguläre Graphen\n",
    "  - Quelle: [Brendan McKay](http://users.cecs.anu.edu.au/~bdm/data/graphs.html)\n",
    "- rantree:\n",
    "  - Format: DIMACS\n",
    "  - Beschreibung: Random Bäume\n",
    "  - Quelle: [Brendan McKay](http://users.cecs.anu.edu.au/~bdm/data/graphs.html)\n",
    "- traing:\n",
    "  - Format: DIMACS\n",
    "  - Beschreibung: Trianguläre Graphen\n",
    "  - Quelle: [Universität Roma](https://pallini.di.uniroma1.it)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Preparation\n",
    "\n",
    "Wir konvertieren alle Graphen in ein einheitliches Format (g6) welches von NetworkX verwendet werden kann.\n",
    "Dazu verwenden wir die Funktion `convert_to_g6` welche die Graphen aus dem DIMACS Format in das g6 Format konvertiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# function to convert the DIMACS graph to a edgelist\n",
    "\n",
    "# list all .gr files in the data folder and convert each file to edgelist\n",
    "for file in glob.glob(\"./data/**/*.dimacs\"):\n",
    "    # remove the 'e ' from the beginning of each line starting with 'e ' and save as .edgelist file\n",
    "    with open(file) as dimacs_file:\n",
    "        lines = dimacs_file.readlines()\n",
    "    with open(file.replace('.dimacs', '.edgelist'), 'w') as edgelist_file:\n",
    "        for line in lines:\n",
    "            if line.startswith('e '):\n",
    "                edgelist_file.write(line[2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet für alle Graphen erstellen\n",
    "\n",
    "dataSets = {}\n",
    "\n",
    "dataSets[\"all_graphs\"] = {}\n",
    "dataSets[\"complete\"] = {}\n",
    "dataSets[\"hypercubes\"] = {}\n",
    "dataSets[\"ran2\"] = {}\n",
    "dataSets[\"ran10\"] = {}\n",
    "dataSets[\"ransq\"] = {}\n",
    "dataSets[\"ranreg\"] = {}\n",
    "dataSets[\"rantree\"] = {}\n",
    "dataSets[\"triang\"] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All_Graphs 3 Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "All_Graphs 4 Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "All_Graphs 5 Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "All_Graphs 6 Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "All_Graphs 7 Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "All_Graphs Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "All_Graphs 8 Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "complete Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "hypercubes Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "ran2 Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "ran10 Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "ransq Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "ranreg Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "rantree Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "triang Progress: |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import networkx as nx\n",
    "\n",
    "# Runs around 12 minutes\n",
    "\n",
    "# Importiere All_Graphs\n",
    "g6_without_10_11 = glob.glob(\"./data/all_graphs/[2-8].g6\")\n",
    "l = len(g6_without_10_11)\n",
    "for (i, f) in enumerate(g6_without_10_11):\n",
    "    filename = Path(f).stem\n",
    "    graphs = nx.read_graph6(f)\n",
    "    printProgressBar(i + 1, l, prefix = 'All_Graphs Progress:', suffix = 'Complete', length = 50)\n",
    "    if type(graphs) == nx.classes.graph.Graph:\n",
    "        dataSets[\"all_graphs\"][filename] = graphs\n",
    "    elif type(graphs) == list:\n",
    "        k = len(graphs)\n",
    "        for (j, graph) in enumerate(graphs):\n",
    "            printProgressBar(j + 1, k, prefix = f\"All_Graphs {filename} Progress:\", suffix = 'Complete', length = 50)\n",
    "            dataSets[\"all_graphs\"][f\"{filename}_{j}\"] = graph\n",
    "\n",
    "# Importiere Complete\n",
    "l = len(glob.glob(\"./data/complete/*.edgelist\"))\n",
    "for (i, f) in enumerate(glob.glob(\"./data/complete/*.edgelist\")):\n",
    "    filename = Path(f).stem\n",
    "    dataSets[\"complete\"][filename] = nx.read_edgelist(f)\n",
    "    printProgressBar(i + 1, l, prefix = 'complete Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "# Importiere Hypercubes\n",
    "l = len(glob.glob(\"./data/hypercubes/*.edgelist\"))\n",
    "for (i, f) in enumerate(glob.glob(\"./data/hypercubes/*.edgelist\")):\n",
    "    filename = Path(f).stem\n",
    "    dataSets[\"hypercubes\"][filename] = nx.read_edgelist(f)\n",
    "    printProgressBar(i + 1, l, prefix = 'hypercubes Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "# Importiere ran2\n",
    "l = len(glob.glob(\"./data/ran2/*.edgelist\"))\n",
    "for (i, f) in enumerate(glob.glob(\"./data/ran2/*.edgelist\")):\n",
    "    filename = Path(f).stem\n",
    "    dataSets[\"ran2\"][filename] = nx.read_edgelist(f)\n",
    "    printProgressBar(i + 1, l, prefix = 'ran2 Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "# Importiere ran10\n",
    "l = len(glob.glob(\"./data/ran10/*.edgelist\"))\n",
    "for (i, f) in enumerate(glob.glob(\"./data/ran10/*.edgelist\")):\n",
    "    filename = Path(f).stem\n",
    "    dataSets[\"ran10\"][filename] = nx.read_edgelist(f)\n",
    "    printProgressBar(i + 1, l, prefix = 'ran10 Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "# Importiere ransq\n",
    "l = len(glob.glob(\"./data/ransq/*.edgelist\"))\n",
    "for (i, f) in enumerate(glob.glob(\"./data/ransq/*.edgelist\")):\n",
    "    filename = Path(f).stem\n",
    "    dataSets[\"ransq\"][filename] = nx.read_edgelist(f)\n",
    "    printProgressBar(i + 1, l, prefix = 'ransq Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "# Importiere ranreg\n",
    "l = len(glob.glob(\"./data/ranreg/*.edgelist\"))\n",
    "for (i, f) in enumerate(glob.glob(\"./data/ranreg/*.edgelist\")):\n",
    "    filename = Path(f).stem\n",
    "    dataSets[\"ranreg\"][filename] = nx.read_edgelist(f)\n",
    "    printProgressBar(i + 1, l, prefix = 'ranreg Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "# Importiere rantree\n",
    "l = len(glob.glob(\"./data/rantree/*.edgelist\"))\n",
    "for (i, f) in enumerate(glob.glob(\"./data/rantree/*.edgelist\")):\n",
    "    filename = Path(f).stem\n",
    "    dataSets[\"rantree\"][filename] = nx.read_edgelist(f)\n",
    "    printProgressBar(i + 1, l, prefix = 'rantree Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "# Importiere triang\n",
    "l = len(glob.glob(\"./data/triang/*.edgelist\"))\n",
    "for (i, f) in enumerate(glob.glob(\"./data/triang/*.edgelist\")):\n",
    "    filename = Path(f).stem\n",
    "    dataSets[\"triang\"][filename] = nx.read_edgelist(f)\n",
    "    printProgressBar(i + 1, l, prefix = 'triang Progress:', suffix = 'Complete', length = 50)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# around 6 min\n",
    "\n",
    "%store dataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 min\n",
    "\n",
    "%store -r dataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the dataSet by keys recursively\n",
    "# keys are string containing numbers inside the string\n",
    "import re\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n",
    "\n",
    "def orderDict(d):\n",
    "    for k, v in d.items():\n",
    "        if type(v) == dict:\n",
    "            d[k] = orderDict(v)\n",
    "    return {k: v for k, v in sorted(d.items(), key=lambda item: natural_keys(item[0]))}\n",
    "\n",
    "\n",
    "orderedDataSets = orderDict(dataSets)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Data Analysis\n",
    "\n",
    "Wir widmen uns nun den Graphen und versuchen ein Gefühl für die Daten zu bekommen. \\\n",
    "Dazu verwenden wir die Funktion `plot_graphs` welche zufällige Grapghen von allen Typen in einem Grid plottet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one graph of each subtype of the dataset in a grid\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def plot_all_graphs(dataSet):\n",
    "    rows = 3\n",
    "    cols = 3\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, 15))\n",
    "    for (i, subType) in enumerate(dataSet):\n",
    "\n",
    "        # get random graph of the subtype\n",
    "        if len(dataSet[subType].keys()) == 0:\n",
    "            continue\n",
    "\n",
    "        # random_graph_key = random.choice(list(dataSet[subType].keys()))\n",
    "        random_graph_key = list(dataSet[subType].keys())[3]\n",
    "        graph = dataSet[subType][random_graph_key]\n",
    "\n",
    "        # break if no graph found for subtype\n",
    "        if len(graph) == 0:\n",
    "            continue\n",
    "        # if we have a list of graphs, take the first one\n",
    "        if not isinstance(graph, nx.Graph):\n",
    "            graph = graph[0]\n",
    "        \n",
    "        # plot graph in the grid\n",
    "        nx.draw(graph, ax=axs[i // cols, i % cols], node_size=15)\n",
    "        axs[i // cols, i % cols].set_title(f\"{subType} - {random_graph_key}\")\n",
    "    plt.show()\n",
    "\n",
    "# plot all graphs of the dataset\n",
    "plot_all_graphs(orderedDataSets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse der topologischen Indices der Graphen\n",
    "\n",
    "Wir wollen nun die topologischen Indices der Graphen untersuchen. Dazu verwenden wir die Funktion `plot_indices` welche die topologischen Indices der Graphen in einem Grid plottet. \\\n",
    "Dazu erstellen wir die Funktion `topological_indices` welche die topologischen Indices der Graphen berechnet. \\\n",
    "Die Funktion erhält einen Graphen und gibt ein Dictionary zurück, welches die topologischen Indices enthält.\n",
    "\n",
    "### Topologische Indices\n",
    "\n",
    "- Wiener Index\n",
    "  - Beschreibung: Summe der kürzesten Pfade zwischen allen Knotenpaaren\n",
    "- Randic Index\n",
    "  - Beschreibung: Misst die Relationen zwischen Knoten und Kanten in einem Graphen\n",
    "- Erster Zagreb Index\n",
    "  - Beschreibung: Der erste Zagreb Index wird berechnet, indem man die Summe der Quadrate der Knotengrade dividiert durch die Anzahl Knoten teilt.\n",
    "- Zweiter Zagreb Index\n",
    "  - Der zweite Zagreb Index wird berechnet, indem man die Summe der Knotengrade durch die Anzahl der Knoten teilt.\n",
    "- Hosoya Index\n",
    "  - Beschreibung: Er wird berechnet, indem man die Summe der Knotengrade durch die Anzahl der Kanten teilt.\n",
    "- Balaban J Index\n",
    "  - Beschreibung: Misst die Ähnlichkeit zwischen den lokalen Strukturen von Graphen\n",
    "\n",
    "- Generalized Randic Index\n",
    "  - Beschreibung: Summe der Eigenwerte der Laplace Matrix\n",
    "- Harmonic Index\n",
    "  - Beschreibung: Summe der Inverse der Eigenwerte der Laplace Matrix\n",
    "- Atom Bond Connectivity Index\n",
    "  - Beschreibung: Summe der Inverse der Eigenwerte der Adjazenzmatrix\n",
    "- Sum Connectivity Index\n",
    "  - Beschreibung: Summe der Inverse der Eigenwerte der Adjazenzmatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grinpy as gp\n",
    "\n",
    "def get_topological_indices(G):\n",
    "    ''' Create a dictionary with the topological indices of a graph G.'''\n",
    "    topological_indices = {}\n",
    "    topological_indices['wiener_index'] = gp.wiener_index(G)\n",
    "    topological_indices['randic_index'] = gp.randic_index(G)\n",
    "    topological_indices['generalized_randic_index'] = gp.generalized_randic_index(G, 2)\n",
    "    topological_indices['harmonic_index'] = gp.harmonic_index(G)\n",
    "    topological_indices['atom_bond_connectivity_index'] = gp.atom_bond_connectivity_index(G)\n",
    "    topological_indices['sum_connectivity_index'] = gp.sum_connectivity_index(G)\n",
    "    topological_indices['first_zagreb_index'] = gp.first_zagreb_index(G)\n",
    "    topological_indices['second_zagreb_index'] = gp.second_zagreb_index(G)\n",
    "\n",
    "    return topological_indices\n",
    "\n",
    "def topological_indices_all_graphs(dataSet):\n",
    "    ''' Create a dictionary with the topological indices of all graphs in the dataset.'''\n",
    "    topological_indices = {}\n",
    "    for subType in dataSet:\n",
    "        topological_indices[subType] = {}\n",
    "        for graph in dataSet[subType]:\n",
    "            topological_indices[subType][graph] = get_topological_indices(dataSet[subType][graph])\n",
    "    return topological_indices\n",
    "\n",
    "topological_indices_all_graphs = topological_indices_all_graphs(dataSets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "403a3ce45d22581176dc371cb15bdaade48159e8b393567367f97e6090235952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
