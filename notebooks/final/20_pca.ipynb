{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Topological Indices\n",
    "\n",
    "## Topological Indices\n",
    "we use the following indices\n",
    "- wiener index\n",
    "- randic index\n",
    "- generalized randic index\n",
    "- harmonic index\n",
    "- atom bond connectivity index\n",
    "- first zagreb index\n",
    "- second zagreb index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to read the dataset from the pickle file\n",
    "import pickle\n",
    "\n",
    "with open('dataset.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "for key in dataset.keys():\n",
    "    print(f\"datasetkey: {key}, shape: {len(dataset[key])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use grinpy to calculate the topological indices for each graph\n",
    "import grinpy as gp\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def get_topological_indices(G):\n",
    "    ''' Create a dictionary with the topological indices of a graph G.'''\n",
    "    topological_indices = {}\n",
    "    topological_indices['wiener_index'] = gp.wiener_index(G)\n",
    "    topological_indices['randic_index'] = gp.randic_index(G)\n",
    "    topological_indices['generalized_randic_index'] = gp.generalized_randic_index(G, 2)\n",
    "    topological_indices['harmonic_index'] = gp.harmonic_index(G)\n",
    "    topological_indices['atom_bond_connectivity_index'] = gp.atom_bond_connectivity_index(G)\n",
    "    topological_indices['first_zagreb_index'] = gp.first_zagreb_index(G)\n",
    "    topological_indices['second_zagreb_index'] = gp.second_zagreb_index(G)\n",
    "\n",
    "    return topological_indices\n",
    "\n",
    "def topological_indices_all_graphs(dataSet, subtypes_to_skip = []):\n",
    "    ''' Create a dictionary with the topological indices of all graphs in the dataset.'''\n",
    "    topological_indices = {}\n",
    "\n",
    "    for key in tqdm(dataSet.keys(), total=4, desc='Calculating TIs for Class'):\n",
    "\n",
    "        if key in subtypes_to_skip:\n",
    "            continue\n",
    "\n",
    "        topological_indices[key] = {}\n",
    "        l = len(dataSet[key])\n",
    "        for (i, graph) in tqdm(enumerate(dataSet[key]), total=l, desc=f'Calculating TIs for {key} graphs'):\n",
    "            topological_indices[key][graph] = get_topological_indices(graph)\n",
    "    return topological_indices\n",
    "\n",
    "\n",
    "subtypes_to_skip = []\n",
    "\n",
    "topological_indices_all_graphs = topological_indices_all_graphs(dataset, subtypes_to_skip)\n",
    "\n",
    "# save the topological indices to a pickle file\n",
    "\n",
    "with open('topological_indices.pickle', 'wb') as f:\n",
    "    pickle.dump(topological_indices_all_graphs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to read the dataset from the pickle file\n",
    "import pickle\n",
    "\n",
    "with open('topological_indices.pickle', 'rb') as f:\n",
    "    topological_indices_all_graphs = pickle.load(f)\n",
    "\n",
    "for key in topological_indices_all_graphs.keys():\n",
    "    print(f\"topological_indices_all_graphs key: {key}, shape: {len(topological_indices_all_graphs[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we perform the PCA on the dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "def topo_numpy_array(topological_indices_subset): \n",
    "    topo_dataset = []\n",
    "    for (i, graph_topo) in enumerate(tqdm(topological_indices_subset)):\n",
    "        graph_ti_dict = topological_indices_subset[graph_topo]\n",
    "        graph_ti_float_values = np.array(list(graph_ti_dict.values()), dtype=float)\n",
    "\n",
    "        if np.any(np.isinf(graph_ti_float_values)):\n",
    "            print(f\"inf in graph {graph_topo}\")\n",
    "            continue\n",
    "        \n",
    "        topo_dataset.append(np.array(graph_ti_float_values))\n",
    "\n",
    "    return topo_dataset\n",
    "\n",
    "\n",
    "def plot_pd_frame(dataset, title):\n",
    "    ''' Plot a pandas dataframe.'''\n",
    "    plt.figure()\n",
    "    dataset.plot()\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pca_dataset(pd_dataset, n_components):\n",
    "    ''' Create a dictionary with the topological indices of all graphs in the dataset.'''\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_res = pca.fit(pd_dataset)\n",
    "    \n",
    "    return pca_res\n",
    "\n",
    "\n",
    "# transform the dictionary into a numpy array\n",
    "topo_dataset_random = topo_numpy_array(topological_indices_all_graphs[\"random\"])\n",
    "topo_dataset_smallworld = topo_numpy_array(topological_indices_all_graphs[\"smallworld\"])\n",
    "topo_dataset_scalefree = topo_numpy_array(topological_indices_all_graphs[\"scalefree\"])\n",
    "topo_dataset_chemical = topo_numpy_array(topological_indices_all_graphs[\"chemical\"])\n",
    "\n",
    "# keys are everywhere the same\n",
    "graph_ti_dict = next(iter(topological_indices_all_graphs[\"random\"].values()))\n",
    "feature_names = list(graph_ti_dict.keys())\n",
    "\n",
    "# normalize data\n",
    "data_scaled_random = pd.DataFrame(preprocessing.scale(topo_dataset_random), columns = feature_names) \n",
    "data_scaled_smallworld = pd.DataFrame(preprocessing.scale(topo_dataset_smallworld), columns = feature_names) \n",
    "data_scaled_scalefree = pd.DataFrame(preprocessing.scale(topo_dataset_scalefree), columns = feature_names) \n",
    "data_scaled_chemical = pd.DataFrame(preprocessing.scale(topo_dataset_chemical), columns = feature_names) \n",
    "\n",
    "# plot scaled / normalized data\n",
    "plot_pd_frame(data_scaled_random, \"random\")\n",
    "plot_pd_frame(data_scaled_smallworld, \"smallworld\")\n",
    "plot_pd_frame(data_scaled_scalefree, \"scalefree\")\n",
    "plot_pd_frame(data_scaled_chemical, \"chemical\")\n",
    "\n",
    "# PCA\n",
    "pca_random_2c = pca_dataset(data_scaled_random, 2)\n",
    "pca_smallworld_2c = pca_dataset(data_scaled_smallworld, 2)\n",
    "pca_scalefree_2c = pca_dataset(data_scaled_scalefree, 2)\n",
    "pca_chemical_2c = pca_dataset(data_scaled_chemical, 2)\n",
    "\n",
    "# print results\n",
    "print(\"------------ PCA random 2 components ------------\")\n",
    "print(pd.DataFrame(pca_random_2c.components_, columns=data_scaled_random.columns, index = ['PC-1','PC-2']))\n",
    "print(\"\")\n",
    "\n",
    "print(\"------------ PCA smallworld 2 components ------------\")\n",
    "print(pd.DataFrame(pca_smallworld_2c.components_, columns=data_scaled_smallworld.columns, index = ['PC-1','PC-2']))\n",
    "print(\"\")\n",
    "\n",
    "print(\"------------ PCA scalefree 2 components ------------\")\n",
    "print(pd.DataFrame(pca_scalefree_2c.components_, columns=data_scaled_scalefree.columns, index = ['PC-1','PC-2']))\n",
    "print(\"\")\n",
    "\n",
    "print(\"------------ PCA chemical 2 components ------------\")\n",
    "print(pd.DataFrame(pca_chemical_2c.components_, columns=data_scaled_chemical.columns, index = ['PC-1','PC-2']))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a biplot using the PCA results\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].scatter(topo_dataset_random[:,0], topo_dataset_random[:,1], c=feature_names)\n",
    "axes[0].set_xlabel('x1')\n",
    "axes[0].set_ylabel('x2')\n",
    "axes[0].set_title('Before PCA')\n",
    "axes[1].scatter(pca_random_2c[:,0], pca_random_2c[:,1], c=feature_names)\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC2')\n",
    "axes[1].set_title('After PCA')\n",
    "plt.show()\n",
    "\n",
    "def biplot(score, coeff, labels=None):\n",
    "\n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "    scalex = 1.0/(xs.max() - xs.min())\n",
    "    scaley = 1.0/(ys.max() - ys.min())\n",
    "    plt.scatter(xs * scalex,ys * scaley, color='blue')\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'r',alpha = 0.5)\n",
    "        if labels is None:\n",
    "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, feature_names[i], color = 'g', ha = 'center', va = 'center')\n",
    "        else:\n",
    "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, labels[i], color = 'g', ha = 'center', va = 'center')\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    plt.xlabel(\"PC{}\".format(1))\n",
    "    plt.ylabel(\"PC{}\".format(2))\n",
    "    plt.grid()\n",
    "\n",
    "# biplot for random\n",
    "\n",
    "biplot(pca_random_2c.transform(data_scaled_random), np.transpose(pca_random_2c.components_), feature_names)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "403a3ce45d22581176dc371cb15bdaade48159e8b393567367f97e6090235952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
