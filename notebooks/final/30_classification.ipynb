{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Classification\n",
    "\n",
    "## Graph Classes\n",
    "\n",
    "we use the following graph classes:\n",
    "- Chemical Graphs (Molecules)\n",
    "- Random\n",
    "- Small World\n",
    "- Scale Free\n",
    "\n",
    "## Setup\n",
    "\n",
    "We use stellargraph to generate the model to train.\n",
    "The model is a GCN with 2 layers and 32 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasetkey: random, shape: 1000\n",
      "datasetkey: smallworld, shape: 1000\n",
      "datasetkey: scalefree, shape: 1000\n",
      "datasetkey: chemical, shape: 6761\n"
     ]
    }
   ],
   "source": [
    "# we need to read the dataset from the pickle file\n",
    "import pickle\n",
    "\n",
    "with open('dataset.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "for key in dataset.keys():\n",
    "    print(f\"datasetkey: {key}, shape: {len(dataset[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset keys are classes\n",
    "# split dataset into train and test\n",
    "import stellargraph as sg\n",
    "from sklearn import model_selection\n",
    "import pandas as pd\n",
    "\n",
    "for key in dataset.keys():\n",
    "    print(f\"datasetkey: {key}, shape: {len(dataset[key])}\")\n",
    "\n",
    "def dataset_to_keras_data(dataset):\n",
    "    \"\"\"\n",
    "        We convert the dictionary which keys are the labels to a list of graphs and a list of labels\n",
    "        The graphs are networkx graphs and need to be converted to StellarGraph objects\n",
    "    \"\"\"\n",
    "    graph_labels = []\n",
    "    graphs = []\n",
    "    for key in dataset.keys():\n",
    "        for graph in dataset[key]:\n",
    "            stellargraph_graph = sg.StellarGraph.from_networkx(graph)\n",
    "            graphs.append(stellargraph_graph)\n",
    "            graph_labels.append(key)\n",
    "\n",
    "    return graphs, graph_labels\n",
    "\n",
    "graphs, graph_labels = dataset_to_keras_data(dataset)\n",
    "print(graphs[0].info())\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    [(g.number_of_nodes(), g.number_of_edges()) for g in graphs],\n",
    "    columns=[\"nodes\", \"edges\"],\n",
    ")\n",
    "summary.describe().round(1)\n",
    "\n",
    "graph_labels.value_counts().to_frame()\n",
    "graph_labels = pd.get_dummies(graph_labels, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "from stellargraph.layer import DeepGraphCNN\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "generator = PaddedGraphGenerator(graphs=graphs)\n",
    "\n",
    "k = 35  # the number of rows for the output tensor\n",
    "layer_sizes = [32, 32, 32, 1]\n",
    "\n",
    "dgcnn_model = DeepGraphCNN(\n",
    "    layer_sizes=layer_sizes,\n",
    "    activations=[\"tanh\", \"tanh\", \"tanh\", \"tanh\"],\n",
    "    k=k,\n",
    "    bias=False,\n",
    "    generator=generator,\n",
    ")\n",
    "x_inp, x_out = dgcnn_model.in_out_tensors()\n",
    "\n",
    "x_out = Conv1D(filters=16, kernel_size=sum(layer_sizes), strides=sum(layer_sizes))(x_out)\n",
    "x_out = MaxPool1D(pool_size=2)(x_out)\n",
    "\n",
    "x_out = Conv1D(filters=32, kernel_size=5, strides=1)(x_out)\n",
    "\n",
    "x_out = Flatten()(x_out)\n",
    "\n",
    "x_out = Dense(units=128, activation=\"relu\")(x_out)\n",
    "x_out = Dropout(rate=0.5)(x_out)\n",
    "\n",
    "predictions = Dense(units=1, activation=\"sigmoid\")(x_out)\n",
    "\n",
    "model = Model(inputs=x_inp, outputs=predictions)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.0001), loss=binary_crossentropy, metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "from sklearn import model_selection\n",
    "import stellargraph as sg\n",
    "\n",
    "\n",
    "train_graphs, test_graphs = model_selection.train_test_split(\n",
    "    graph_labels, train_size=0.9, test_size=None, stratify=graph_labels,\n",
    ")\n",
    "\n",
    "gen = PaddedGraphGenerator(graphs=graphs)\n",
    "\n",
    "train_gen = gen.flow(\n",
    "    list(train_graphs.index - 1),\n",
    "    targets=train_graphs.values,\n",
    "    batch_size=50,\n",
    "    symmetric_normalization=False,\n",
    ")\n",
    "\n",
    "test_gen = gen.flow(\n",
    "    list(test_graphs.index - 1),\n",
    "    targets=test_graphs.values,\n",
    "    batch_size=1,\n",
    "    symmetric_normalization=False,\n",
    ")\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen, epochs=epochs, verbose=1, validation_data=test_gen, shuffle=True,\n",
    ")\n",
    "\n",
    "sg.utils.plot_history(history)\n",
    "\n",
    "test_metrics = model.evaluate(test_gen)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c27191ed4da92fbef1e06f47803eae1586514922c69f32c30cb3a0fae2806a55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
